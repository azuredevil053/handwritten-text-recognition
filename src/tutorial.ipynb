{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tutorial.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":["oMty1YwuWHpN","39blvPTPQJpt","QVBGMLifWQwl","WyLRbAwsWSYA"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"gP-v0E_S-mQP","colab_type":"text"},"source":["<img src=\"https://github.com/arthurflor23/handwritten-text-recognition/blob/master/doc/images/000.png?raw=true\" />\n","\n","# Handwritten Text Recognition using TensorFlow 2.0\n","\n","This tutorial shows how you can use the project of [Handwritten Text Recognition](https://github.com/arthurflor23/handwritten-text-recognition) in your Google Colab.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"oMty1YwuWHpN","colab_type":"text"},"source":["## 1 Localhost Environment\n","\n","We'll make sure you have the project in your Google Drive with the datasets in HDF5. If you already have structured files in the cloud, skip this step."]},{"cell_type":"markdown","metadata":{"id":"39blvPTPQJpt","colab_type":"text"},"source":["### 1.1 Datasets\n","\n","The datasets that you can use:\n","\n","a. [Bentham](http://transcriptorium.eu/datasets/bentham-collection/)\n","\n","b. [IAM](http://www.fki.inf.unibe.ch/databases/iam-handwriting-database)\n","\n","c. [Rimes](http://www.a2ialab.com/doku.php?id=rimes_database:start)\n","\n","d. [Saint Gall](http://www.fki.inf.unibe.ch/databases/iam-historical-document-database/saint-gall-database)"]},{"cell_type":"markdown","metadata":{"id":"QVBGMLifWQwl","colab_type":"text"},"source":["### 1.2 Raw folder\n","\n","On localhost, download the code project from GitHub and extract the chosen dataset (or all if you prefer) in the **raw** folder. Don't change anything of the structure of the dataset, since the scripts were made from the **original structure** of them. Your project directory will be like this:\n","\n","```\n",".\n","├── doc\n","│   ├── images\n","│   └── results\n","├── LICENSE\n","├── raw\n","│   ├── bentham\n","│   │   ├── BenthamDatasetR0-GT\n","│   │   └── BenthamDatasetR0-Images\n","│   ├── iam\n","│   │   ├── ascii\n","│   │   ├── forms\n","│   │   ├── largeWriterIndependentTextLineRecognitionTask\n","│   │   ├── lines\n","│   │   └── xml\n","│   ├── rimes\n","│   │   ├── eval_2011\n","│   │   ├── eval_2011_annotated.xml\n","│   │   ├── training_2011\n","│   │   └── training_2011.xml\n","│   └── saintgall\n","│       ├── data\n","│       ├── ground_truth\n","│       ├── README.txt\n","│       └── sets\n","├── README.md\n","├── requirements.txt\n","└── src\n","    ├── data\n","    │   ├── generator.py\n","    │   ├── preproc.py\n","    ├── main.py\n","    ├── network\n","    │   ├── architecture.py\n","    │   ├── gated.py\n","    │   ├── model.py\n","    ├── transform\n","    │   ├── bentham.py\n","    │   ├── iam.py\n","    │   ├── rimes.py\n","    │   └── saintgall.py\n","    └── tutorial.ipynb\n","\n","```\n","\n","After that, create virtual environment and install the dependencies with python 3 and pip:\n","\n","> ```python -m venv .venv && source .venv/bin/activate```\n","\n","> ```pip install -r requirements.txt```"]},{"cell_type":"markdown","metadata":{"id":"WyLRbAwsWSYA","colab_type":"text"},"source":["### 1.3 HDF5 files\n","\n","Now, you'll run the *transform* function from **main.py**. For this, execute on **src** folder:\n","\n","> ```python main.py --dataset=<DATASET_NAME> --transform```\n","\n","Your data will be preprocess and encode, creating and saving in the **data** folder. Now your project directory will be like this:\n","\n","\n","```\n",".\n","├── data\n","│   ├── bentham.hdf5\n","│   ├── iam.hdf5\n","│   ├── rimes.hdf5\n","│   └── saintgall.hdf5\n","├── doc\n","│   ├── images\n","│   └── results\n","├── LICENSE\n","├── raw\n","│   ├── bentham\n","│   │   ├── BenthamDatasetR0-GT\n","│   │   └── BenthamDatasetR0-Images\n","│   ├── iam\n","│   │   ├── ascii\n","│   │   ├── forms\n","│   │   ├── largeWriterIndependentTextLineRecognitionTask\n","│   │   ├── lines\n","│   │   └── xml\n","│   ├── rimes\n","│   │   ├── eval_2011\n","│   │   ├── eval_2011_annotated.xml\n","│   │   ├── training_2011\n","│   │   └── training_2011.xml\n","│   └── saintgall\n","│       ├── data\n","│       ├── ground_truth\n","│       ├── README.txt\n","│       └── sets\n","├── README.md\n","├── requirements.txt\n","└── src\n","    ├── data\n","    │   ├── generator.py\n","    │   ├── preproc.py\n","    ├── main.py\n","    ├── network\n","    │   ├── architecture.py\n","    │   ├── gated.py\n","    │   ├── model.py\n","    ├── transform\n","    │   ├── bentham.py\n","    │   ├── iam.py\n","    │   ├── rimes.py\n","    │   └── saintgall.py\n","    └── tutorial.ipynb\n","\n","```\n","\n","Then upload the **data** and **src** folders in the same directory in your Google Drive."]},{"cell_type":"markdown","metadata":{"id":"jydsAcWgWVth","colab_type":"text"},"source":["## 2 Google Drive Environment\n"]},{"cell_type":"markdown","metadata":{"id":"wk3e7YJiXzSl","colab_type":"text"},"source":["### 2.1 TensorFlow 2.0"]},{"cell_type":"markdown","metadata":{"id":"Z7twXyNGXtbJ","colab_type":"text"},"source":["Make sure the jupyter notebook is using GPU mode. Try to use **Tesla T4** instead of Tesla K80 (faster)."]},{"cell_type":"code","metadata":{"id":"mHw4tODULT1Z","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","\n","device_name = tf.test.gpu_device_name()\n","\n","if device_name != \"/device:GPU:0\":\n","    raise SystemError(\"GPU device not found\")\n","\n","print(f\"Found GPU at: {device_name}\\n\")\n","\n","!nvidia-smi"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UJECz8H8XVCY","colab_type":"text"},"source":["Now, we'll install TensorFlow 2.0 with GPU support."]},{"cell_type":"code","metadata":{"id":"FMg-B5PH9h3r","colab_type":"code","colab":{}},"source":["!pip install -q tensorflow-gpu==2.0.0-beta1"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FyMv5wyDXxqc","colab_type":"text"},"source":["### 2.2 Google Drive"]},{"cell_type":"markdown","metadata":{"id":"P5gj6qwoX9W3","colab_type":"text"},"source":["Mount your Google Drive partition.\n","\n","**Note:** *\\\"Colab Notebooks/handwritten-text-recognition/src/\\\"* was the directory where you put the project folders, specifically the **src** folder."]},{"cell_type":"code","metadata":{"id":"ACQn1iBF9k9O","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","\n","drive.mount(\"./gdrive\")\n","\n","%cd \"./gdrive/My Drive/Colab Notebooks/handwritten-text-recognition/src/\"\n","!ls -l"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YwogUA8RZAyp","colab_type":"text"},"source":["After mount, you can see the list os files in the project folder."]},{"cell_type":"markdown","metadata":{"id":"-fj7fSngY1IX","colab_type":"text"},"source":["## 3 Set Python Classes"]},{"cell_type":"markdown","metadata":{"id":"p6Q4cOlWhNl3","colab_type":"text"},"source":["### 3.1 Environment"]},{"cell_type":"markdown","metadata":{"id":"wvqL2Eq5ZUc7","colab_type":"text"},"source":["First, let's define our environment variables.\n","\n","Set the main configuration parameters, like input size, batch size, number of epochs and list of characters. This make compatible with **main.py** and jupyter notebook:\n","\n","* **dataset**: \"bentham\", \"iam\", \"rimes\", \"saintgall\"\n","\n","* **arch**: network to run: \"bluche\", \"puigcerver\", \"flor\"\n","\n","* **epochs**: number of epochs\n","\n","* **batch_size**: number size of the batch"]},{"cell_type":"code","metadata":{"id":"_Qpr3drnGMWS","colab_type":"code","colab":{}},"source":["import os\n","\n","# define parameters\n","dataset = \"iam\"\n","arch = \"flor\"\n","epochs = 1000\n","batch_size = 16\n","\n","# define paths\n","hdf5_src = os.path.join(\"..\", \"data\", f\"{dataset}.hdf5\")\n","output = os.path.join(\"..\", \"output\", f\"{dataset}_{arch}\")\n","\n","# define input size, number max of chars per line and list of valid chars\n","input_size = (1024, 128, 1)\n","max_text_length = 128\n","charset = \"\".join([chr(i) for i in range(32, 127)])\n","\n","print(\"source:\", hdf5_src)\n","print(\"output\", output)\n","print(\"charset:\", charset)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BFextshOhTKr","colab_type":"text"},"source":["### 3.2 DataGenerator Class"]},{"cell_type":"markdown","metadata":{"id":"KfZ1mfvsanu1","colab_type":"text"},"source":["The second class is **DataGenerator()**, responsible for:\n","\n","* Load the dataset partitions (train, valid, test);\n","\n","* Manager batchs for train/validation/test process."]},{"cell_type":"code","metadata":{"id":"8k9vpNzMIAi2","colab_type":"code","colab":{}},"source":["from data.generator import DataGenerator\n","\n","dtgen = DataGenerator(hdf5_src=hdf5_src,\n","                      batch_size=batch_size,\n","                      max_text_length=max_text_length)\n","\n","print(f\"Train images: {dtgen.total_train}\")\n","print(f\"Validation images: {dtgen.total_valid}\")\n","print(f\"Test images: {dtgen.total_test}\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-OdgNLK0hYAA","colab_type":"text"},"source":["### 3.3 HTRModel Class"]},{"cell_type":"markdown","metadata":{"id":"jHktk8AFcnKy","colab_type":"text"},"source":["The third class is **HTRModel()**, was developed to be easy to use and to abstract the complicated flow of a HTR system. It's responsible for:\n","\n","* Create model with Handwritten Text Recognition flow, in which calculate the loss function by CTC and decode output to calculate the HTR metrics (CER, WER, SER);\n","\n","* Save and load models;\n","\n","* Load weights in the models, if exists;\n","\n","* Make Train/Predict process using *generator*.\n","\n","To make a dynamic HTRModel, its parameters are the *input_layer* and *output_layer* from your own network (default code has Bluche and Puigcerver implementations on **network/architecture.py**).\n","The last parameter is the list of chars you want to work with (default is 96 chars from ASCII)."]},{"cell_type":"code","metadata":{"id":"nV0GreStISTR","colab_type":"code","colab":{}},"source":["from network.model import HTRModel\n","from network import architecture\n","\n","# get the input_layer, output_layer and optimizer from default network\n","network_func = getattr(architecture, arch)\n","ioo = network_func(input_size=input_size, output_size=len(charset) + 1)\n","\n","# initiate and compile the HTRModel\n","model = HTRModel(inputs=ioo[0], outputs=ioo[1], charset=charset)\n","model.compile(optimizer=ioo[2])\n","\n","# save network summary\n","model.summary(output, \"summary.txt\")\n","\n","# load checkpoint weights (HDF5) if exists and get default callbacks\n","checkpoint = \"checkpoint_weights.hdf5\"\n","\n","model.load_checkpoint(output, checkpoint)\n","callbacks = model.callbacks(logdir=output, hdf5_target=checkpoint)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KASq6zqogG6Q","colab_type":"text"},"source":["## 4 Tensorboard"]},{"cell_type":"markdown","metadata":{"id":"T8eBxuoogM-d","colab_type":"text"},"source":["To facilitate the visualization of the model's training, you can instantiate the Tensorboard. \n","\n","**Note**: All data is saved in the output folder"]},{"cell_type":"code","metadata":{"id":"bPx4hRHuJGAd","colab_type":"code","colab":{}},"source":["%load_ext tensorboard\n","%tensorboard --reload_interval=180 --logdir={output}"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T1fnz0Eugqru","colab_type":"text"},"source":["## 5 Training"]},{"cell_type":"markdown","metadata":{"id":"w1mLOcqYgsO-","colab_type":"text"},"source":["The training process is similar to the *fit_generator* of the Keras. After training, the information (epochs and minimum loss) is save."]},{"cell_type":"code","metadata":{"id":"2P6MSoxCISlD","colab_type":"code","colab":{}},"source":["import time\n","\n","# to calculate total and average time per epoch\n","start_time = time.time()\n","\n","h = model.fit_generator(generator=dtgen.next_train_batch(),\n","                        epochs=epochs,\n","                        steps_per_epoch=dtgen.train_steps,\n","                        validation_data=dtgen.next_valid_batch(),\n","                        validation_steps=dtgen.valid_steps,\n","                        callbacks=callbacks,\n","                        shuffle=True,\n","                        verbose=1)\n","\n","total_time = time.time() - start_time\n","\n","loss = h.history['loss']\n","val_loss = h.history['val_loss']\n","\n","min_val_loss = min(val_loss)\n","min_val_loss_i = val_loss.index(min_val_loss)\n","\n","train_corpus = \"\\n\".join([\n","    f\"Total train images:       {dtgen.total_train}\",\n","    f\"Total validation images:  {dtgen.total_valid}\",\n","    f\"Batch:                    {batch_size}\\n\",\n","    f\"Total time:               {(total_time / 60):.0f} min\",\n","    f\"Average time per epoch:   {(total_time / len(loss)):.0f} sec\\n\",\n","    f\"Total epochs:             {len(loss)}\",\n","    f\"Best epoch                {min_val_loss_i + 1}\\n\",\n","    f\"Training loss:            {loss[min_val_loss_i]:.4f}\",\n","    f\"Validation loss:          {min_val_loss:.4f}\"\n","])\n","\n","with open(os.path.join(output, \"train.txt\"), \"w\") as lg:\n","    print(f\"\\n{train_corpus}\")\n","    lg.write(train_corpus)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"13g7tDjWgtXV","colab_type":"text"},"source":["## 6 Predict/Evaluate"]},{"cell_type":"markdown","metadata":{"id":"ddO26OT-g_QK","colab_type":"text"},"source":["The predict function mescle two functionalities: (1) *predict*, (2) *evaluate*.\n","\n","The predict process is similar to the *predict_generator* of the Keras, but has one more parameter **metrics**. If, you pass this parameter, will be calculate metrics (loss, cer, wer, ser) and get the predictions yet. After that, the information (predicts and metrics) is save in output directory."]},{"cell_type":"code","metadata":{"id":"a9iHL6tmaL_j","colab_type":"code","colab":{}},"source":["# predict[0]: ground truth\n","# predict[1]: predict\n","# evaluate: metrics parameter\n","predict, evaluate = model.predict_generator(generator=dtgen.next_test_batch(),\n","                                            steps=dtgen.test_steps,\n","                                            metrics=[\"loss\", \"cer\", \"wer\", \"ser\"],\n","                                            verbose=1)\n","\n","# save evaluation\n","eval_corpus = \"\\n\".join([\n","    f\"Total test images:    {dtgen.total_test}\\n\",\n","    f\"Metrics:\",\n","    f\"Test Loss:            {evaluate[0]:.4f}\",\n","    f\"Character Error Rate: {evaluate[1]:.4f}\",\n","    f\"Word Error Rate:      {evaluate[2]:.4f}\",\n","    f\"Sequence Error Rate:  {evaluate[3]:.4f}\"\n","])\n","\n","with open(os.path.join(output, \"evaluate.txt\"), \"w\") as lg:\n","    lg.write(eval_corpus)\n","    print(f\"\\n{eval_corpus}\")\n","\n","# save predicts\n","pred_corpus = \"\\n\".join([f\"L: {l}\\nP: {p}\\n\" for (l, p) in zip(predict[0], predict[1])])\n","\n","with open(os.path.join(output, \"predict.txt\"), \"w\") as lg:\n","    lg.write(pred_corpus)"],"execution_count":0,"outputs":[]}]}